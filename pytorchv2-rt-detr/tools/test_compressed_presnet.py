#!/usr/bin/env python3
"""Sanity-check compressed ResNet hot path using synthetic inputs.

The script instantiates the ResNet34 backbone with the compressed-input wrapper,
feeds it batches of DCT coefficients generated by ``CompressToDCT`` for a list
of spatial sizes, and prints the resulting feature / logit shapes.  This keeps
all work out of the training loop, making it easy to verify shapes or trace
issues introduced by the decompression stage.
"""

from __future__ import annotations

import argparse
from typing import Iterable, List

import torch

from src.nn.backbone.train_backbones import build_model, _IMAGENET_MEAN, _IMAGENET_STD
from src.nn.backbone.compressed_presnet import build_compressed_backbone
from src.data.transforms.compress_reference_images import CompressToDCT
from src.nn.arch.classification import ClassHead
from src.misc.dct_coefficients import resolve_coefficient_counts

try:  # Optional dependency for FLOP accounting
    from fvcore.nn import FlopCountAnalysis  # type: ignore
except ImportError:  # pragma: no cover - optional metrics
    FlopCountAnalysis = None


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--model",
        default="resnet34",
        choices=["resnet34"],
        help="Backbone preset to test (compressed path currently available for ResNet34).",
    )
    parser.add_argument(
        "--sizes",
        type=int,
        nargs="+",
        default=[224, 240, 256, 320],
        help="Spatial resolutions (multiples of 8) to feed through the compressed path.",
    )
    parser.add_argument(
        "--coeff-window",
        type=int,
        default=8,
        choices=[1, 2, 4, 8],
        help="Low-frequency window used when generating DCT blocks.",
    )
    parser.add_argument(
        "--range-mode",
        default="studio",
        choices=["studio", "full"],
        help="Range fed into CompressToDCT prior to the forward DCT.",
    )
    parser.add_argument(
        "--variant",
        default="reconstruction",
        choices=["reconstruction", "block-stem", "luma-fusion", "luma-fusion-pruned"],
        help="Compressed backbone variant to evaluate.",
    )
    parser.add_argument(
        "--device",
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Device for the model and synthetic batch.",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=1234,
        help="Random seed for synthetic RGB inputs.",
    )
    return parser.parse_args()


def _ensure_multiple_of(values: Iterable[int], divisor: int = 8) -> List[int]:
    cleaned: List[int] = []
    for value in values:
        if value % divisor != 0:
            raise ValueError(f"Spatial size {value} is not divisible by {divisor}.")
        cleaned.append(value)
    return cleaned


def build_wrapped_model(device: torch.device, range_mode: str, variant: str, coeff_window: int) -> torch.nn.Module:
    model, _ = build_model("resnet34", num_classes=1000)
    _, coeff_count_luma, coeff_count_cb, coeff_count_cr = resolve_coefficient_counts(
        coeff_window=coeff_window,
    )
    coeff_count_chroma = coeff_count_cb if coeff_count_cb == coeff_count_cr else max(coeff_count_cb, coeff_count_cr)
    model.backbone = build_compressed_backbone(
        variant,
        model.backbone,
        range_mode=range_mode,
        mean=_IMAGENET_MEAN,
        std=_IMAGENET_STD,
        coeff_window_luma=coeff_window,
        coeff_window_chroma=coeff_window,
        coeff_count_luma=coeff_count_luma,
        coeff_count_chroma=coeff_count_chroma,
        coeff_count_cb=coeff_count_cb,
        coeff_count_cr=coeff_count_cr,
    )
    if variant == "luma-fusion-pruned":
        hidden_dim = model.backbone.out_channels[0]
        model.head = ClassHead(hidden_dim=hidden_dim, num_classes=1000)
    model.to(device)
    model.eval()
    return model


def build_compressor(coeff_window: int, range_mode: str) -> CompressToDCT:
    return CompressToDCT(
        coeff_window=coeff_window,
        range_mode=range_mode,
        dtype=torch.float32,
        keep_original=False,
    )


def format_feature_shapes(features) -> str:
    if isinstance(features, (list, tuple)):
        return ", ".join(str(tuple(feat.shape)) for feat in features)
    return str(tuple(features.shape))


def main() -> None:
    args = parse_args()
    device = torch.device(args.device)
    sizes = _ensure_multiple_of(args.sizes)

    torch.manual_seed(args.seed)

    model = build_wrapped_model(device, args.range_mode, args.variant, args.coeff_window)
    compressor = build_compressor(args.coeff_window, args.range_mode)

    print("Testing compressed inference path:")
    print(f"  device: {device}")
    print(f"  coeff window: {args.coeff_window}")
    print(f"  range mode: {args.range_mode}")
    print(f"  variant: {args.variant}")
    print("  sizes:", ", ".join(str(x) for x in sizes))

    total_params = sum(p.numel() for p in model.parameters())
    print(f"  parameters: {total_params / 1e6:.2f} M")
    if FlopCountAnalysis is None:
        print("  FLOPs: fvcore not installed (pip install fvcore for flop stats)")

    with torch.no_grad():
        for size in sizes:
            rgb = torch.rand(3, size, size)
            y_blocks, cbcr_blocks = compressor(rgb)
            batch = (
                y_blocks.unsqueeze(0).to(device=device),
                cbcr_blocks.unsqueeze(0).to(device=device),
            )

            flop_msg = ""
            if FlopCountAnalysis is not None:
                try:
                    flops = FlopCountAnalysis(model, (batch,)).total()
                    flop_msg = f" | FLOPs {flops / 1e9:.2f}G"
                except Exception as err:  # pragma: no cover
                    flop_msg = f" | FLOPs n/a ({err})"

            backbone_features = model.backbone(batch)
            logits = model.head(backbone_features)

            print(
                f"size {size:3d} â†’ logits {tuple(logits.shape)} | features {format_feature_shapes(backbone_features)}{flop_msg}"
            )


if __name__ == "__main__":
    main()
